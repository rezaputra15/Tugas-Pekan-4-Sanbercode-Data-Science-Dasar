{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrQVcF-ldGWQ"
   },
   "source": [
    "<h1> Soal 1: Pemahaman Tentang Model Evaluasi</h1>\n",
    "\n",
    "Jawab pertanyaan di bawah ini dengan bahasa masing-masing?\n",
    "\n",
    "1. Apa perbedaan antara data latih, data validasi, dan data test?\n",
    "2. Bagaimana cara kita menilai performa suatu model?\n",
    "3. Apa itu Confusion Matrix? Jelaskan secara lengkap!\n",
    "4. Apa itu Classification Report dari sklearn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sr6D5UIhgpwO"
   },
   "source": [
    "Jawab:\n",
    "1. Data Training, seperti namanya, data yang digunakan untuk training model. Sejauh ini kita telah melakukan tersebut. Data Validation, digunakan untuk proses validasi model dan mencegah overfitting. Data Testing, digunakan untuk testing model, sebagai simulasi penggunaan model pada dunia nyata. Data testing tidak boleh pernah dilihat oleh model sebelumnya.\n",
    "2. Untuk mengukur kinerja model yang telah dibuat, performance metrics populer yang umum dan sering digunakan: accuracy, precission, dan recall. Accuracy menggambarkan seberapa akurat model dapat mengklasifikasikan dengan benar. Maka, accuracy merupakan rasio prediksi benar (positif dan negatif) dengan keseluruhan data. Dengan kata lain, accuracy merupakan tingkat kedekatan nilai prediksi dengan nilai aktual (sebenarnya). Nilai accuracy dapat diperoleh dengan persamaan (1). Precision menggambarkan tingkat keakuratan antara data yang diminta dengan hasil prediksi yang diberikan oleh model. Maka, precision merupakan rasio prediksi benar positif dibandingkan dengan keseluruhan hasil yang diprediksi positf. Dari semua kelas positif yang telah di prediksi dengan benar, berapa banyak data yang benar-benar positif. Nilai precision dapat diperoleh dengan persamaan (2). Recall menggambarkan keberhasilan model dalam menemukan kembali sebuah informasi. Maka, recall merupakan rasio prediksi benar positif dibandingkan dengan keseluruhan data yang benar positif. Nilai recall dapat diperoleh dengan persamaan (3).\n",
    "3. Confusion matrix juga sering disebut error matrix. Pada dasarnya confusion matrix memberikan informasi perbandingan hasil klasifikasi yang dilakukan oleh sistem (model) dengan hasil klasifikasi sebenarnya. Confusion matrix berbentuk tabel matriks yang menggambarkan kinerja model klasifikasi pada serangkaian data uji yang nilai sebenarnya diketahui.\n",
    "4. Classification report digunakan untuk mengukur kualitas prediksi dari algoritma classification. Berapa banyak prediksi yang True dan berapa banyak yang False. Lebih khusus lagi, True Positive, False Positive, True negative dan False Negatives digunakan untuk memprediksi metrik classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uY-s7-KDgrkV"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fv2TVsgAdGWY"
   },
   "source": [
    "<h1>Soal 2: Aplikasi Model Evaluasi</h1>\n",
    "\n",
    "Kali ini kita akan menggunakan data untuk memprediksi kelangsungan hidup pasien yang telah mengalami operasi payudara. Dengan informasi yang dimiliki terkait pasien, kita akan membuat model untuk memprediksi apakah pasien akan bertahan hidup dalam waktu lebih dari 5 tahun atau tidak.\n",
    "\n",
    "Lebih Lengkapnya kalian bisa membaca informasi tentang dataset di link berikut: https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.names\n",
    "\n",
    "Buat model Klasifikasi (Model/Algoritma Bebas) untuk memprediksi status pasien dengan ketentuan sebagai berikut:\n",
    "\n",
    "1. Bagi kedua data ini menjadi data training dan data test dengan test_size=0.25.\n",
    "3. Pelajar tentang metrics roc_auc_score kemudian buatlah model dan evaluasi dengan menggunakan teknik cross-validation dengan scoring 'roc_auc'. Baca https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html untuk menggunakan metric roc_auc saat cross-validation.\n",
    "3. Berapa score rata2 dari model dengan teknik cross-validation tersebut?\n",
    "4. Prediksi data test dengan model yang telah kalian buat!\n",
    "5. Bagaimana hasil confusion matrix dari hasil prediksi tersebut?\n",
    "6. Bagaimana classification report dari hasil prediksi tersebut?\n",
    "5. Seberapa baik model anda dalam memprediksi seorang pasien mempunyai status positive?\n",
    "6. Seberapa baik model anda dalam memprediksi seorang pasien mempunyai status negatif?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4UqaWyPdGWj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.csv'\n",
    "list_cols = ['Age', \"Patient's Years\", \"N_positive_ax\", \"survival_status\"]\n",
    "df = pd.read_csv(url, names=list_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrbPNGtHdGXV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Patient's Years</th>\n",
       "      <th>N_positive_ax</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Patient's Years  N_positive_ax  survival_status\n",
       "0   30               64              1                1\n",
       "1   30               62              3                1\n",
       "2   30               65              0                1\n",
       "3   31               59              2                1\n",
       "4   31               65              4                1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-dxYNPg7dGX4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    225\n",
       "2     81\n",
       "Name: survival_status, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['survival_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8W2amvZgdGYX"
   },
   "outputs": [],
   "source": [
    "# Code here\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "x = df.drop('survival_status',axis=1)\n",
    "y = df['survival_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6182751427316645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, stratify=y, random_state=21)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=2)\n",
    "model_knn.fit(x_train,y_train)\n",
    "\n",
    "#Cross val score\n",
    "cv = cross_val_score(model_knn, x, y, cv=10, scoring='roc_auc')\n",
    "display(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict data test\n",
    "y_predict = model_knn.predict(x_test)\n",
    "\n",
    "score = accuracy_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  7],\n",
       "       [14,  6]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confussion matrix\n",
    "confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 14],\n",
       "       [ 7, 50]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confussion matrix\n",
    "confusion_matrix(y_test,y_predict, labels=[2,1]) #<- label positif, negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 6\n",
    "FN = 14\n",
    "FP = 7\n",
    "TN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.88      0.83        57\n",
      "           2       0.46      0.30      0.36        20\n",
      "\n",
      "    accuracy                           0.73        77\n",
      "   macro avg       0.62      0.59      0.60        77\n",
      "weighted avg       0.70      0.73      0.71        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "#menghitung nilai presisi, recall, f1-score dari model kita dalam memprediksi data yang positif\n",
    "precision = TP/(TP+FP)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "recall = TP/(TP+FN)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3636363636363637\n"
     ]
    }
   ],
   "source": [
    "f1score = 2*precision*recall/(precision+recall)\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78125\n"
     ]
    }
   ],
   "source": [
    "#menghitung nilai presisi, recall, f1-score dari model kita dalam memprediksi data yang negatif\n",
    "precision1 = TN/(TN+FN)\n",
    "print(precision1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8771929824561403\n"
     ]
    }
   ],
   "source": [
    "recall1 = TN/(TN+FP)\n",
    "print(recall1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8264462809917354\n"
     ]
    }
   ],
   "source": [
    "f1score1 = 2*precision1*recall1/(precision1+recall1)\n",
    "print(f1score1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6v_dgoN-7wL"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teekoyIw--g2"
   },
   "source": [
    "<h1> Soal 3: Pemahaman Tentang Model Selection</h1>\n",
    "\n",
    "Jelaskan dengan bahasa sendiri!\n",
    "\n",
    "1. Apa itu Bias dan Variance?\n",
    "2. Apa itu Overfitting dan Underfitting?\n",
    "3. Apa yang bisa kita lakukan untuk mengatur kompleksitas dari model?\n",
    "4. Bagaimana model yang baik?\n",
    "5. Kapan kita menggunakan GridSearchcv dan kapan menggunakan RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4a1l4RNf_FcU"
   },
   "source": [
    "Jawab:\n",
    "1. Bias adalah perbedaan antara rata rata hasil prediksi dari model ML yang kita develop dengan data nilai yang sebenarnya. Bias yang tinggi dikarenakan dalam pembangunan model ML, dilakukan terlalu sederhan (oversimplified). Faktor penyebab lain dikarenakan model ML yang di develop terlalu tidak terlalu berinteraksi dengan training data. Variance adalah variabel dari prediksi model untuk data tertentu dimana memberikan kita informasi perserbaran data kita. Model yang memiliki variance tinggi sangat memperhatikan hanya pada train data. High variance model, perform baik di train data. Tetapi jika disuguhkan data baru yang belum pernah ditemukan di train data. Model tersebut tidak dapat mengeneralisasikan secara baik dari identifikasi data baru tersebut. \n",
    "2. Underfitting terjadi ketika model tidak bisa melihat logika dibelakang data, hingga tidak bisa melakukan prediksi dengan tepat, baik untuk dataset training maupun dataset lain yang serupa. Underfitting model akan memiliki high loss dan akurasi rendah. Overfitting terjadi karena model yang dibuat terlalu fokus pada training dataset tertentu, hingga tidak bisa melakukan prediksi dengan tepat jika diberikan dataset lain yang serupa. Overfitting biasanya akan menangkap data noise yang seharusnya diabaikan. Overfitting model akan memiliki low loss dan akurasi rendah.\n",
    "3. Kompleksitas dari model ditentukan oleh Bias error, variance error, high variance, high bias dan error total. Bias error disebabkan oleh model yang terlalu simple. Variance error disebabkan oleh model yang terlalu kompleks. High bias yaitu error di data training dan validasi besar. High variance yaitu error di data training kecil dan di validasinya kecil ataupun sebaliknya.\n",
    "4. Model yang baik merupakan model yang memiliki bias error dan variance error yang kecil\n",
    "5. GridSearchcv digunakan saat akan mencoba semua hyperparameter yang mungkin dan RandomizedSearchCV digunakan saat memilih hyperparameter beberapa saja secara random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Svj_cgxF_IZv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hkh-PeRL_LZp"
   },
   "source": [
    "<h1> Soal 4: Aplikasi Model Selection</h1>\n",
    "\n",
    "1. Bagi kedua data berikut ini menjadi data training dan data test dengan test_size=0.25.\n",
    "2. Gunakan algoritma KNN sebagai model classifier.\n",
    "3. Gunakan fungsi GridSearchCV untuk hyperparameter tuning dan model selection.\n",
    "4. jumlah fold bebas!, gunakan scoring 'roc_auc'\n",
    "5. Definisikan kombinasi hyperparameter untuk model selection dengan GridSearchCV. kombinasi Hyperparameter bebas, baca lagi dokumentasi KNN di link berikut https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html untuk memahami lagi jenis2 hyperparameter di algorithma KNN.\n",
    "6. Latih model terhadap data training.\n",
    "7. Apa hyperparameter terbaik untuk kombinasi hyperparameter kalian?\n",
    "8. Berapa score validasi terbaik dari model tersebut?\n",
    "9. Prediksi probabilitasi output dari model yang telah di buat terhadap data test. note : gunakan method .predict_proba() untuk menghasilkan output probabilitas\n",
    "10. Perhatikan bahwa hasil prediksi ada 2, dimana masing2 adalah nilai probabilitas untuk setiap class label. Ambil nilai probabilitas pasien phositive meninggal dalam waktu kurang dari 5 tahun. note : gunakan bantuan attirubte .classes_ untuk mengetahui urutan label dari hasil prediksi probabilitas.\n",
    "11. Berapa nilai score roc_auc untuk data test?\n",
    "12. Apakah model anda termasuk baik, overtting, atau underfitting?\n",
    "13. Ulangi tahap di atas namun kali ini menggunakan algoritma DecisionTreeClassifier dan kalian bisa menggunakan RandomizedSearchCV apabila process training lama. pelajari algoritma DecisionTreeClassifier di linkberikut: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier\n",
    "14. Bandingkan scorenya dengan Algoritma KNN, mana yang lebih baik?\n",
    "\n",
    "Note : Data Science adalah experiment, sangat di dimungkinkan memerlukan beberapa kali percobaan untuk mendapatkan hasil yang terbaik! Happy Coding :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_zK8Mqb-9Z6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.csv'\n",
    "list_cols = ['Age', \"Patient's Years\", \"N_positive_ax\", \"survival_status\"]\n",
    "df = pd.read_csv(url, names=list_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qb-AD43R_V_d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Patient's Years</th>\n",
       "      <th>N_positive_ax</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Patient's Years  N_positive_ax  survival_status\n",
       "0   30               64              1                1\n",
       "1   30               62              3                1\n",
       "2   30               65              0                1\n",
       "3   31               59              2                1\n",
       "4   31               65              4                1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('survival_status',axis=1)\n",
    "y = df['survival_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       "                         'weights': ['distance', 'uniform']},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors' : np.arange(5,50),\n",
    "    'weights' : ['distance','uniform']\n",
    "}\n",
    "gscv = GridSearchCV(model, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
    "gscv.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 40, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7151062091503269"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.725, 0.275],\n",
       "       [0.725, 0.275],\n",
       "       [0.65 , 0.35 ],\n",
       "       [0.5  , 0.5  ],\n",
       "       [0.7  , 0.3  ],\n",
       "       [0.825, 0.175],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.75 , 0.25 ],\n",
       "       [0.7  , 0.3  ],\n",
       "       [0.375, 0.625],\n",
       "       [0.875, 0.125],\n",
       "       [0.75 , 0.25 ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.925, 0.075],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.75 , 0.25 ],\n",
       "       [0.775, 0.225],\n",
       "       [0.475, 0.525],\n",
       "       [0.875, 0.125],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.375, 0.625],\n",
       "       [0.875, 0.125],\n",
       "       [0.925, 0.075],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.875, 0.125],\n",
       "       [0.9  , 0.1  ],\n",
       "       [0.825, 0.175],\n",
       "       [0.9  , 0.1  ],\n",
       "       [0.425, 0.575],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.475, 0.525],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.875, 0.125],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.5  , 0.5  ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.75 , 0.25 ],\n",
       "       [0.55 , 0.45 ],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.925, 0.075],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.9  , 0.1  ],\n",
       "       [0.875, 0.125],\n",
       "       [0.4  , 0.6  ],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.4  , 0.6  ],\n",
       "       [0.875, 0.125],\n",
       "       [0.775, 0.225],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.5  , 0.5  ],\n",
       "       [0.825, 0.175],\n",
       "       [0.375, 0.625],\n",
       "       [0.45 , 0.55 ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.75 , 0.25 ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.75 , 0.25 ],\n",
       "       [0.75 , 0.25 ],\n",
       "       [0.775, 0.225],\n",
       "       [0.75 , 0.25 ],\n",
       "       [0.65 , 0.35 ],\n",
       "       [0.925, 0.075],\n",
       "       [0.725, 0.275],\n",
       "       [0.875, 0.125],\n",
       "       [0.75 , 0.25 ],\n",
       "       [0.425, 0.575],\n",
       "       [0.75 , 0.25 ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.4  , 0.6  ]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_validate(model_knn, x, y, cv=10, scoring='roc_auc', return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6182751427316645"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, stratify=y, random_state=21)\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(x_train, y_train)\n",
    "y_pred = model_tree.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.592594537815126"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "acc_Tree = cross_val_score(model_tree, x_train, y_train, cv=10, scoring='roc_auc').mean()\n",
    "acc_Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 40, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7151062091503269"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(), n_iter=20,\n",
       "                   param_distributions={'n_neighbors': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       "                                        'weights': ['distance', 'uniform']},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, stratify=y, random_state=21)\n",
    "model = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors' : np.arange(5,50),\n",
    "    'weights' : ['distance','uniform']\n",
    "}\n",
    "rscv = RandomizedSearchCV(model, param_grid, cv=5, scoring='roc_auc', n_iter=20)\n",
    "rscv.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'uniform', 'n_neighbors': 48}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7080147058823529"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72916667, 0.27083333],\n",
       "       [0.75      , 0.25      ],\n",
       "       [0.70833333, 0.29166667],\n",
       "       [0.52083333, 0.47916667],\n",
       "       [0.6875    , 0.3125    ],\n",
       "       [0.79166667, 0.20833333],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.77083333, 0.22916667],\n",
       "       [0.6875    , 0.3125    ],\n",
       "       [0.41666667, 0.58333333],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.75      , 0.25      ],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.85416667, 0.14583333],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.77083333, 0.22916667],\n",
       "       [0.75      , 0.25      ],\n",
       "       [0.79166667, 0.20833333],\n",
       "       [0.52083333, 0.47916667],\n",
       "       [0.89583333, 0.10416667],\n",
       "       [0.85416667, 0.14583333],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.39583333, 0.60416667],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.85416667, 0.14583333],\n",
       "       [0.85416667, 0.14583333],\n",
       "       [0.85416667, 0.14583333],\n",
       "       [0.85416667, 0.14583333],\n",
       "       [0.4375    , 0.5625    ],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.52083333, 0.47916667],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.79166667, 0.20833333],\n",
       "       [0.85416667, 0.14583333],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.85416667, 0.14583333],\n",
       "       [0.79166667, 0.20833333],\n",
       "       [0.60416667, 0.39583333],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.89583333, 0.10416667],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.39583333, 0.60416667],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.41666667, 0.58333333],\n",
       "       [0.89583333, 0.10416667],\n",
       "       [0.79166667, 0.20833333],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.54166667, 0.45833333],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.41666667, 0.58333333],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.77083333, 0.22916667],\n",
       "       [0.85416667, 0.14583333],\n",
       "       [0.72916667, 0.27083333],\n",
       "       [0.79166667, 0.20833333],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.75      , 0.25      ],\n",
       "       [0.6875    , 0.3125    ],\n",
       "       [0.89583333, 0.10416667],\n",
       "       [0.77083333, 0.22916667],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.79166667, 0.20833333],\n",
       "       [0.45833333, 0.54166667],\n",
       "       [0.77083333, 0.22916667],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.41666667, 0.58333333]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.predict_proba(x_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tugas Hari 3 Pekan 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
